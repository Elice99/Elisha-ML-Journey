{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5006dfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SALES PIPELINE PREDICTION - COMPLETE IMPLEMENTATION\n",
    "# ============================================================================\n",
    "# This code walks through every step with detailed comments\n",
    "# ============================================================================\n",
    "\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# For modeling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score, \n",
    "                             recall_score, f1_score, confusion_matrix, \n",
    "                             classification_report, roc_curve, auc)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Set style for visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ec1246b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 1: LOADING AND EXPLORING DATA\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"PHASE 1: LOADING AND EXPLORING DATA\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c0cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = pyodbc.connect(\n",
    "    \"Driver={SQL Server};\"\n",
    "    \"Server=ELICE99\\\\SQLEXPRESS;\"\n",
    "    \"Database=CRM_Sales_Opportunity;\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac4b04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data loaded: 8300 records\n",
      "✓ Columns: 17\n"
     ]
    }
   ],
   "source": [
    "# Query to get data (excluding 'Prospecting' stage)\n",
    "query = '''\n",
    "SELECT p.*, \n",
    "    a.sector, a.year_established, a.account_tier, a.employees, a.office_location,\n",
    "    s.manager, s.regional_office\n",
    "FROM dbo.sales_pipeline p\n",
    "LEFT JOIN accounts a ON a.account = p.account\n",
    "LEFT JOIN sales_teams s ON p.sales_agent = s.sales_agent\n",
    "WHERE deal_stage NOT IN ('Prospecting')\n",
    "'''\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"✓ Data loaded: {len(df)} records\")\n",
    "print(f\"✓ Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e96030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " EXPLORATORY DATA ANALYSIS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7727848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First few rows:\n",
      "  opportunity_id      sales_agent         product  account deal_stage  \\\n",
      "0       1C1I7A6R      Moses Frase  GTX Plus Basic  Cancity        Won   \n",
      "1       Z063OYW0  Darcel Schlecht          GTXPro    Isdom        Won   \n",
      "2       EC4QE1BX  Darcel Schlecht      MG Special  Cancity        Won   \n",
      "3       MV1LWRNH      Moses Frase       GTX Basic  Codehow        Won   \n",
      "4       PE84CX4O        Zane Levy       GTX Basic   Hatfan        Won   \n",
      "\n",
      "  engage_date  close_date  close_value  is_active  deal_duration    sector  \\\n",
      "0  2016-10-20  2017-03-01         1054      False          132.0    Retail   \n",
      "1  2016-10-25  2017-03-11         4514      False          137.0   Medical   \n",
      "2  2016-10-25  2017-03-07           50      False          133.0    Retail   \n",
      "3  2016-10-25  2017-03-09          588      False          135.0  Software   \n",
      "4  2016-10-25  2017-03-02          517      False          128.0  Services   \n",
      "\n",
      "   year_established      account_tier  employees office_location  \\\n",
      "0            2001.0  Large_Enterprise     2448.0   United States   \n",
      "1            2002.0  Large_Enterprise     4540.0   United States   \n",
      "2            2001.0  Large_Enterprise     2448.0   United States   \n",
      "3            1998.0  Large_Enterprise     2641.0   United States   \n",
      "4            1982.0  Large_Enterprise     1299.0   United States   \n",
      "\n",
      "            manager regional_office  \n",
      "0  Dustin Brinkmann         Central  \n",
      "1     Melvin Marxen         Central  \n",
      "2     Melvin Marxen         Central  \n",
      "3  Dustin Brinkmann         Central  \n",
      "4     Summer Sewald            West  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b678d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types:\n",
      "opportunity_id       object\n",
      "sales_agent          object\n",
      "product              object\n",
      "account              object\n",
      "deal_stage           object\n",
      "engage_date          object\n",
      "close_date           object\n",
      "close_value           int64\n",
      "is_active              bool\n",
      "deal_duration       float64\n",
      "sector               object\n",
      "year_established    float64\n",
      "account_tier         object\n",
      "employees           float64\n",
      "office_location      object\n",
      "manager              object\n",
      "regional_office      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd893cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n",
      "close_date          1589\n",
      "deal_duration       1589\n",
      "account_tier        1088\n",
      "office_location     1088\n",
      "year_established    1088\n",
      "sector              1088\n",
      "employees           1088\n",
      "opportunity_id         0\n",
      "sales_agent            0\n",
      "is_active              0\n",
      "close_value            0\n",
      "engage_date            0\n",
      "deal_stage             0\n",
      "product                0\n",
      "account                0\n",
      "manager                0\n",
      "regional_office        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2eb44cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Statistics:\n",
      "        close_value  deal_duration  year_established     employees\n",
      "count   8300.000000    6711.000000       7212.000000   7212.000000\n",
      "mean    1205.486024      47.985397       1995.454104   5737.717277\n",
      "std     2167.597195      41.057665          9.186596   6850.680603\n",
      "min        0.000000       1.000000       1979.000000      9.000000\n",
      "25%        0.000000       8.000000       1988.000000   1238.000000\n",
      "50%       49.000000      45.000000       1995.000000   3492.000000\n",
      "75%     1136.000000      85.000000       2002.000000   7523.000000\n",
      "max    30288.000000     138.000000       2017.000000  34288.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae00416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(34288.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['employees'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9610c149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     7212.000000\n",
       "mean      5737.717277\n",
       "std       6850.680603\n",
       "min          9.000000\n",
       "50%       3492.000000\n",
       "90%      16499.000000\n",
       "95%      17479.000000\n",
       "99%      34288.000000\n",
       "max      34288.000000\n",
       "Name: employees, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['employees'].describe(percentiles=[0.9,0.95,0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log transformation\n",
    "df[\"employees_log\"]= np.log1p(df['employees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e77e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#company size category\n",
    "\n",
    "bins = [0, 50, 250, 1000, 5000, 15000, np.inf]\n",
    "labels = ['micro', 'small', 'medium', 'large', 'enterprise', 'mega']\n",
    "df [\"company_size\"] = pd.cut(df['employees'], bins=bins, labels=labels).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA CLEANING & LEAKAGE PREVENTION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA CLEANING & LEAKAGE PREVENTION\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e733677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names (lowercase, underscores)\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92c9d4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Column names and values standardized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standardize string values\n",
    "string_cols = df.select_dtypes(include='object').columns\n",
    "for col in string_cols:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_')\n",
    "\n",
    "print(\"✓ Column names and values standardized\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e990391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original deal_stage distribution:\n",
      "deal_stage\n",
      "won         4238\n",
      "lost        2473\n",
      "engaging    1589\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# CRITICAL: Keep only CLOSED deals (won or lost) for training\n",
    "print(\"\\nOriginal deal_stage distribution:\")\n",
    "print(df['deal_stage'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After filtering:\n",
      "Training data (won + lost): 6711 rows\n",
      "Active deals (to predict): 1589 rows\n"
     ]
    }
   ],
   "source": [
    "# Filter: Keep only won and lost deals for training\n",
    "df_training = df[df['deal_stage'].isin(['won', 'lost'])].copy()\n",
    "\n",
    "# Save active deals separately for later predictions\n",
    "df_active = df[df['deal_stage'] == 'engaging'].copy()\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(f\"Training data (won + lost): {len(df_training)} rows\")\n",
    "print(f\"Active deals (to predict): {len(df_active)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "433643e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opportunity_id</th>\n",
       "      <th>sales_agent</th>\n",
       "      <th>product</th>\n",
       "      <th>account</th>\n",
       "      <th>deal_stage</th>\n",
       "      <th>engage_date</th>\n",
       "      <th>close_date</th>\n",
       "      <th>close_value</th>\n",
       "      <th>is_active</th>\n",
       "      <th>deal_duration</th>\n",
       "      <th>sector</th>\n",
       "      <th>year_established</th>\n",
       "      <th>account_tier</th>\n",
       "      <th>employees</th>\n",
       "      <th>office_location</th>\n",
       "      <th>manager</th>\n",
       "      <th>regional_office</th>\n",
       "      <th>employees_log</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1c1i7a6r</td>\n",
       "      <td>moses_frase</td>\n",
       "      <td>gtx_plus_basic</td>\n",
       "      <td>cancity</td>\n",
       "      <td>won</td>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>1054</td>\n",
       "      <td>False</td>\n",
       "      <td>132.0</td>\n",
       "      <td>retail</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>large_enterprise</td>\n",
       "      <td>2448.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>dustin_brinkmann</td>\n",
       "      <td>central</td>\n",
       "      <td>7.803435</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z063oyw0</td>\n",
       "      <td>darcel_schlecht</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>isdom</td>\n",
       "      <td>won</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>2017-03-11</td>\n",
       "      <td>4514</td>\n",
       "      <td>False</td>\n",
       "      <td>137.0</td>\n",
       "      <td>medical</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>large_enterprise</td>\n",
       "      <td>4540.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>8.420903</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ec4qe1bx</td>\n",
       "      <td>darcel_schlecht</td>\n",
       "      <td>mg_special</td>\n",
       "      <td>cancity</td>\n",
       "      <td>won</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>133.0</td>\n",
       "      <td>retail</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>large_enterprise</td>\n",
       "      <td>2448.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>7.803435</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mv1lwrnh</td>\n",
       "      <td>moses_frase</td>\n",
       "      <td>gtx_basic</td>\n",
       "      <td>codehow</td>\n",
       "      <td>won</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>588</td>\n",
       "      <td>False</td>\n",
       "      <td>135.0</td>\n",
       "      <td>software</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>large_enterprise</td>\n",
       "      <td>2641.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>dustin_brinkmann</td>\n",
       "      <td>central</td>\n",
       "      <td>7.879291</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pe84cx4o</td>\n",
       "      <td>zane_levy</td>\n",
       "      <td>gtx_basic</td>\n",
       "      <td>hatfan</td>\n",
       "      <td>won</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>517</td>\n",
       "      <td>False</td>\n",
       "      <td>128.0</td>\n",
       "      <td>services</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>large_enterprise</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>summer_sewald</td>\n",
       "      <td>west</td>\n",
       "      <td>7.170120</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8295</th>\n",
       "      <td>2eblr9n8</td>\n",
       "      <td>lajuana_vencill</td>\n",
       "      <td>gtx_basic</td>\n",
       "      <td>conecom</td>\n",
       "      <td>won</td>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>622</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>technolgy</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>large_enterprise</td>\n",
       "      <td>1806.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>dustin_brinkmann</td>\n",
       "      <td>central</td>\n",
       "      <td>7.499423</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8296</th>\n",
       "      <td>vdga4kxa</td>\n",
       "      <td>violet_mclelland</td>\n",
       "      <td>gtx_plus_basic</td>\n",
       "      <td>bluth_company</td>\n",
       "      <td>won</td>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>1093</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>technolgy</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>large_enterprise</td>\n",
       "      <td>3027.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>cara_losch</td>\n",
       "      <td>east</td>\n",
       "      <td>8.015658</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8297</th>\n",
       "      <td>6wcnnk5j</td>\n",
       "      <td>maureen_marcano</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>hottechi</td>\n",
       "      <td>won</td>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>4433</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>technolgy</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>large_enterprise</td>\n",
       "      <td>16499.0</td>\n",
       "      <td>korea</td>\n",
       "      <td>summer_sewald</td>\n",
       "      <td>west</td>\n",
       "      <td>9.711116</td>\n",
       "      <td>mega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8298</th>\n",
       "      <td>yjtqsz9d</td>\n",
       "      <td>gladys_colclough</td>\n",
       "      <td>gtx_plus_basic</td>\n",
       "      <td>inity</td>\n",
       "      <td>won</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>2017-12-30</td>\n",
       "      <td>1052</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>marketing</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>large_enterprise</td>\n",
       "      <td>8801.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>9.082734</td>\n",
       "      <td>enterprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8299</th>\n",
       "      <td>rb8gdyfy</td>\n",
       "      <td>gladys_colclough</td>\n",
       "      <td>mg_special</td>\n",
       "      <td>betatech</td>\n",
       "      <td>won</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>67</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>medical</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>large_enterprise</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>kenya</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>7.078342</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6711 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     opportunity_id       sales_agent         product        account  \\\n",
       "0          1c1i7a6r       moses_frase  gtx_plus_basic        cancity   \n",
       "1          z063oyw0   darcel_schlecht          gtxpro          isdom   \n",
       "2          ec4qe1bx   darcel_schlecht      mg_special        cancity   \n",
       "3          mv1lwrnh       moses_frase       gtx_basic        codehow   \n",
       "4          pe84cx4o         zane_levy       gtx_basic         hatfan   \n",
       "...             ...               ...             ...            ...   \n",
       "8295       2eblr9n8   lajuana_vencill       gtx_basic        conecom   \n",
       "8296       vdga4kxa  violet_mclelland  gtx_plus_basic  bluth_company   \n",
       "8297       6wcnnk5j   maureen_marcano          gtxpro       hottechi   \n",
       "8298       yjtqsz9d  gladys_colclough  gtx_plus_basic          inity   \n",
       "8299       rb8gdyfy  gladys_colclough      mg_special       betatech   \n",
       "\n",
       "     deal_stage engage_date  close_date  close_value  is_active  \\\n",
       "0           won  2016-10-20  2017-03-01         1054      False   \n",
       "1           won  2016-10-25  2017-03-11         4514      False   \n",
       "2           won  2016-10-25  2017-03-07           50      False   \n",
       "3           won  2016-10-25  2017-03-09          588      False   \n",
       "4           won  2016-10-25  2017-03-02          517      False   \n",
       "...         ...         ...         ...          ...        ...   \n",
       "8295        won  2017-12-24  2017-12-26          622      False   \n",
       "8296        won  2017-12-24  2017-12-30         1093      False   \n",
       "8297        won  2017-12-26  2017-12-29         4433      False   \n",
       "8298        won  2017-12-27  2017-12-30         1052      False   \n",
       "8299        won  2017-12-27  2017-12-29           67      False   \n",
       "\n",
       "      deal_duration     sector  year_established      account_tier  employees  \\\n",
       "0             132.0     retail            2001.0  large_enterprise     2448.0   \n",
       "1             137.0    medical            2002.0  large_enterprise     4540.0   \n",
       "2             133.0     retail            2001.0  large_enterprise     2448.0   \n",
       "3             135.0   software            1998.0  large_enterprise     2641.0   \n",
       "4             128.0   services            1982.0  large_enterprise     1299.0   \n",
       "...             ...        ...               ...               ...        ...   \n",
       "8295            2.0  technolgy            2005.0  large_enterprise     1806.0   \n",
       "8296            6.0  technolgy            1993.0  large_enterprise     3027.0   \n",
       "8297            3.0  technolgy            1997.0  large_enterprise    16499.0   \n",
       "8298            3.0  marketing            1986.0  large_enterprise     8801.0   \n",
       "8299            2.0    medical            1986.0  large_enterprise     1185.0   \n",
       "\n",
       "     office_location           manager regional_office  employees_log  \\\n",
       "0      united_states  dustin_brinkmann         central       7.803435   \n",
       "1      united_states     melvin_marxen         central       8.420903   \n",
       "2      united_states     melvin_marxen         central       7.803435   \n",
       "3      united_states  dustin_brinkmann         central       7.879291   \n",
       "4      united_states     summer_sewald            west       7.170120   \n",
       "...              ...               ...             ...            ...   \n",
       "8295   united_states  dustin_brinkmann         central       7.499423   \n",
       "8296   united_states        cara_losch            east       8.015658   \n",
       "8297           korea     summer_sewald            west       9.711116   \n",
       "8298   united_states     melvin_marxen         central       9.082734   \n",
       "8299           kenya     melvin_marxen         central       7.078342   \n",
       "\n",
       "     company_size  \n",
       "0           large  \n",
       "1           large  \n",
       "2           large  \n",
       "3           large  \n",
       "4           large  \n",
       "...           ...  \n",
       "8295        large  \n",
       "8296        large  \n",
       "8297         mega  \n",
       "8298   enterprise  \n",
       "8299        large  \n",
       "\n",
       "[6711 rows x 19 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d78dccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Removing leakage columns...\n",
      "Leakage columns removed: close_date, close_value, is_active, deal_duration, opportunity_id, employees, account_tier\n"
     ]
    }
   ],
   "source": [
    "# CRITICAL: DROP LEAKAGE COLUMNS\n",
    "print(\"\\nRemoving leakage columns...\")\n",
    "leakage_columns = ['close_date', 'close_value', 'is_active','deal_duration', 'opportunity_id','employees', 'account_tier']\n",
    "df_training = df_training.drop(columns=leakage_columns, errors='ignore')\n",
    "df_active = df_active.drop(columns=leakage_columns, errors='ignore')\n",
    "\n",
    "print(\"Leakage columns removed: close_date, close_value, is_active, deal_duration, opportunity_id, employees, account_tier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6680974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATE TARGET VARIABLE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATE TARGET VARIABLE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Distribution:\n",
      "target\n",
      "0    4238\n",
      "1    2473\n",
      "Name: count, dtype: int64\n",
      "\n",
      "lost Rate: 36.85%\n"
     ]
    }
   ],
   "source": [
    "# Create binary target: 0 = Won, 1 = Lost\n",
    "df_training['target'] = (df_training['deal_stage'] == 'lost').astype(int)\n",
    "\n",
    "print(\"\\nTarget Distribution:\")\n",
    "print(df_training['target'].value_counts())\n",
    "print(f\"\\nlost Rate: {df_training['target'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Drop deal_stage column (no longer needed)\n",
    "df_training = df_training.drop('deal_stage', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37d3d368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_agent</th>\n",
       "      <th>product</th>\n",
       "      <th>account</th>\n",
       "      <th>engage_date</th>\n",
       "      <th>sector</th>\n",
       "      <th>year_established</th>\n",
       "      <th>office_location</th>\n",
       "      <th>manager</th>\n",
       "      <th>regional_office</th>\n",
       "      <th>employees_log</th>\n",
       "      <th>company_size</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moses_frase</td>\n",
       "      <td>gtx_plus_basic</td>\n",
       "      <td>cancity</td>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>retail</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>dustin_brinkmann</td>\n",
       "      <td>central</td>\n",
       "      <td>7.803435</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>darcel_schlecht</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>isdom</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>medical</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>8.420903</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>darcel_schlecht</td>\n",
       "      <td>mg_special</td>\n",
       "      <td>cancity</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>retail</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>7.803435</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moses_frase</td>\n",
       "      <td>gtx_basic</td>\n",
       "      <td>codehow</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>software</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>dustin_brinkmann</td>\n",
       "      <td>central</td>\n",
       "      <td>7.879291</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zane_levy</td>\n",
       "      <td>gtx_basic</td>\n",
       "      <td>hatfan</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>services</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>summer_sewald</td>\n",
       "      <td>west</td>\n",
       "      <td>7.170120</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8295</th>\n",
       "      <td>lajuana_vencill</td>\n",
       "      <td>gtx_basic</td>\n",
       "      <td>conecom</td>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>technolgy</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>dustin_brinkmann</td>\n",
       "      <td>central</td>\n",
       "      <td>7.499423</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8296</th>\n",
       "      <td>violet_mclelland</td>\n",
       "      <td>gtx_plus_basic</td>\n",
       "      <td>bluth_company</td>\n",
       "      <td>2017-12-24</td>\n",
       "      <td>technolgy</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>cara_losch</td>\n",
       "      <td>east</td>\n",
       "      <td>8.015658</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8297</th>\n",
       "      <td>maureen_marcano</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>hottechi</td>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>technolgy</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>korea</td>\n",
       "      <td>summer_sewald</td>\n",
       "      <td>west</td>\n",
       "      <td>9.711116</td>\n",
       "      <td>mega</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8298</th>\n",
       "      <td>gladys_colclough</td>\n",
       "      <td>gtx_plus_basic</td>\n",
       "      <td>inity</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>marketing</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>9.082734</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8299</th>\n",
       "      <td>gladys_colclough</td>\n",
       "      <td>mg_special</td>\n",
       "      <td>betatech</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>medical</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>kenya</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>7.078342</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6711 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sales_agent         product        account engage_date     sector  \\\n",
       "0          moses_frase  gtx_plus_basic        cancity  2016-10-20     retail   \n",
       "1      darcel_schlecht          gtxpro          isdom  2016-10-25    medical   \n",
       "2      darcel_schlecht      mg_special        cancity  2016-10-25     retail   \n",
       "3          moses_frase       gtx_basic        codehow  2016-10-25   software   \n",
       "4            zane_levy       gtx_basic         hatfan  2016-10-25   services   \n",
       "...                ...             ...            ...         ...        ...   \n",
       "8295   lajuana_vencill       gtx_basic        conecom  2017-12-24  technolgy   \n",
       "8296  violet_mclelland  gtx_plus_basic  bluth_company  2017-12-24  technolgy   \n",
       "8297   maureen_marcano          gtxpro       hottechi  2017-12-26  technolgy   \n",
       "8298  gladys_colclough  gtx_plus_basic          inity  2017-12-27  marketing   \n",
       "8299  gladys_colclough      mg_special       betatech  2017-12-27    medical   \n",
       "\n",
       "      year_established office_location           manager regional_office  \\\n",
       "0               2001.0   united_states  dustin_brinkmann         central   \n",
       "1               2002.0   united_states     melvin_marxen         central   \n",
       "2               2001.0   united_states     melvin_marxen         central   \n",
       "3               1998.0   united_states  dustin_brinkmann         central   \n",
       "4               1982.0   united_states     summer_sewald            west   \n",
       "...                ...             ...               ...             ...   \n",
       "8295            2005.0   united_states  dustin_brinkmann         central   \n",
       "8296            1993.0   united_states        cara_losch            east   \n",
       "8297            1997.0           korea     summer_sewald            west   \n",
       "8298            1986.0   united_states     melvin_marxen         central   \n",
       "8299            1986.0           kenya     melvin_marxen         central   \n",
       "\n",
       "      employees_log company_size  target  \n",
       "0          7.803435        large       0  \n",
       "1          8.420903        large       0  \n",
       "2          7.803435        large       0  \n",
       "3          7.879291        large       0  \n",
       "4          7.170120        large       0  \n",
       "...             ...          ...     ...  \n",
       "8295       7.499423        large       0  \n",
       "8296       8.015658        large       0  \n",
       "8297       9.711116         mega       0  \n",
       "8298       9.082734   enterprise       0  \n",
       "8299       7.078342        large       0  \n",
       "\n",
       "[6711 rows x 12 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00ea228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PHASE 8: TRAIN-TEST SPLIT\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 8: TRAIN-TEST SPLIT\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd7e8283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5368, 1343)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train, df_test = train_test_split(df_training, test_size=0.2, random_state=1)\n",
    "len(df_full_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d5388f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4026, 1343, 1342)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "len(df_train), len(df_test), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable (y) from the features (X) for the training and test sets\n",
    "y_train = df_train.target.values\n",
    "y_val = df_val.target.values\n",
    "y_test = df_test.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7752adab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_agent</th>\n",
       "      <th>product</th>\n",
       "      <th>account</th>\n",
       "      <th>engage_date</th>\n",
       "      <th>sector</th>\n",
       "      <th>year_established</th>\n",
       "      <th>office_location</th>\n",
       "      <th>manager</th>\n",
       "      <th>regional_office</th>\n",
       "      <th>employees_log</th>\n",
       "      <th>company_size</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elease_gluck</td>\n",
       "      <td>gtk_500</td>\n",
       "      <td>cheers</td>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>celia_rouche</td>\n",
       "      <td>west</td>\n",
       "      <td>8.775395</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cassey_cress</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>ontomedia</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>employment</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>rocco_neubert</td>\n",
       "      <td>east</td>\n",
       "      <td>7.926603</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kary_hendrixson</td>\n",
       "      <td>mg_advanced</td>\n",
       "      <td>y-corporation</td>\n",
       "      <td>2017-07-08</td>\n",
       "      <td>employment</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>summer_sewald</td>\n",
       "      <td>west</td>\n",
       "      <td>9.165552</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>darcel_schlecht</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>rangreen</td>\n",
       "      <td>2017-09-21</td>\n",
       "      <td>technolgy</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>panama</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>9.079776</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marty_freudenburg</td>\n",
       "      <td>mg_advanced</td>\n",
       "      <td>inity</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>marketing</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>9.082734</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>vicki_laflamme</td>\n",
       "      <td>mg_advanced</td>\n",
       "      <td>goodsilron</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>marketing</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>celia_rouche</td>\n",
       "      <td>west</td>\n",
       "      <td>8.538563</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5364</th>\n",
       "      <td>versie_hillebrand</td>\n",
       "      <td>gtx_plus_pro</td>\n",
       "      <td>inity</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>marketing</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>dustin_brinkmann</td>\n",
       "      <td>central</td>\n",
       "      <td>9.082734</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>hayden_neloms</td>\n",
       "      <td>mg_advanced</td>\n",
       "      <td>hottechi</td>\n",
       "      <td>2017-07-13</td>\n",
       "      <td>technolgy</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>korea</td>\n",
       "      <td>celia_rouche</td>\n",
       "      <td>west</td>\n",
       "      <td>9.711116</td>\n",
       "      <td>mega</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5366</th>\n",
       "      <td>vicki_laflamme</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>hatfan</td>\n",
       "      <td>2016-12-19</td>\n",
       "      <td>services</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>celia_rouche</td>\n",
       "      <td>west</td>\n",
       "      <td>7.170120</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367</th>\n",
       "      <td>kami_bicknell</td>\n",
       "      <td>gtx_plus_basic</td>\n",
       "      <td>j-texon</td>\n",
       "      <td>2017-09-09</td>\n",
       "      <td>retail</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>summer_sewald</td>\n",
       "      <td>west</td>\n",
       "      <td>8.184235</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5368 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sales_agent         product        account engage_date  \\\n",
       "0          elease_gluck         gtk_500         cheers  2017-06-15   \n",
       "1          cassey_cress          gtxpro      ontomedia  2017-02-25   \n",
       "2       kary_hendrixson     mg_advanced  y-corporation  2017-07-08   \n",
       "3       darcel_schlecht          gtxpro       rangreen  2017-09-21   \n",
       "4     marty_freudenburg     mg_advanced          inity  2017-03-01   \n",
       "...                 ...             ...            ...         ...   \n",
       "5363     vicki_laflamme     mg_advanced     goodsilron  2017-02-25   \n",
       "5364  versie_hillebrand    gtx_plus_pro          inity  2017-09-10   \n",
       "5365      hayden_neloms     mg_advanced       hottechi  2017-07-13   \n",
       "5366     vicki_laflamme          gtxpro         hatfan  2016-12-19   \n",
       "5367      kami_bicknell  gtx_plus_basic        j-texon  2017-09-09   \n",
       "\n",
       "             sector  year_established office_location           manager  \\\n",
       "0     entertainment            1993.0   united_states      celia_rouche   \n",
       "1        employment            1997.0   united_states     rocco_neubert   \n",
       "2        employment            1983.0   united_states     summer_sewald   \n",
       "3         technolgy            1987.0          panama     melvin_marxen   \n",
       "4         marketing            1986.0   united_states     melvin_marxen   \n",
       "...             ...               ...             ...               ...   \n",
       "5363      marketing            2000.0   united_states      celia_rouche   \n",
       "5364      marketing            1986.0   united_states  dustin_brinkmann   \n",
       "5365      technolgy            1997.0           korea      celia_rouche   \n",
       "5366       services            1982.0   united_states      celia_rouche   \n",
       "5367         retail            1989.0   united_states     summer_sewald   \n",
       "\n",
       "     regional_office  employees_log company_size  target  \n",
       "0               west       8.775395   enterprise       0  \n",
       "1               east       7.926603        large       0  \n",
       "2               west       9.165552   enterprise       1  \n",
       "3            central       9.079776   enterprise       1  \n",
       "4            central       9.082734   enterprise       1  \n",
       "...              ...            ...          ...     ...  \n",
       "5363            west       8.538563   enterprise       0  \n",
       "5364         central       9.082734   enterprise       1  \n",
       "5365            west       9.711116         mega       1  \n",
       "5366            west       7.170120        large       0  \n",
       "5367            west       8.184235        large       0  \n",
       "\n",
       "[5368 rows x 12 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True) # Reset the index of the new dataframes to ensure a clean sequential index from 0\n",
    "df_full_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d19ec3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_agent</th>\n",
       "      <th>product</th>\n",
       "      <th>account</th>\n",
       "      <th>engage_date</th>\n",
       "      <th>sector</th>\n",
       "      <th>year_established</th>\n",
       "      <th>office_location</th>\n",
       "      <th>manager</th>\n",
       "      <th>regional_office</th>\n",
       "      <th>employees_log</th>\n",
       "      <th>company_size</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>gladys_colclough</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>toughzap</td>\n",
       "      <td>2017-02-22</td>\n",
       "      <td>retail</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>6.684612</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>darcel_schlecht</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>streethex</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>retail</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>belgium</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>7.061334</td>\n",
       "      <td>large</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>darcel_schlecht</td>\n",
       "      <td>mg_advanced</td>\n",
       "      <td>dontechi</td>\n",
       "      <td>2017-05-13</td>\n",
       "      <td>software</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>9.218705</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>kary_hendrixson</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>kan-code</td>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>software</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>summer_sewald</td>\n",
       "      <td>west</td>\n",
       "      <td>10.442580</td>\n",
       "      <td>mega</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7122</th>\n",
       "      <td>marty_freudenburg</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>warephase</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>services</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>8.571113</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>corliss_cosme</td>\n",
       "      <td>gtxpro</td>\n",
       "      <td>betasoloin</td>\n",
       "      <td>2016-11-25</td>\n",
       "      <td>medical</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>cara_losch</td>\n",
       "      <td>east</td>\n",
       "      <td>6.206576</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>jonathan_berthelot</td>\n",
       "      <td>mg_special</td>\n",
       "      <td>streethex</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>retail</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>belgium</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>7.061334</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>kary_hendrixson</td>\n",
       "      <td>gtx_basic</td>\n",
       "      <td>goodsilron</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>marketing</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>summer_sewald</td>\n",
       "      <td>west</td>\n",
       "      <td>8.538563</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>jonathan_berthelot</td>\n",
       "      <td>gtx_plus_basic</td>\n",
       "      <td>isdom</td>\n",
       "      <td>2017-06-18</td>\n",
       "      <td>medical</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>melvin_marxen</td>\n",
       "      <td>central</td>\n",
       "      <td>8.420903</td>\n",
       "      <td>large</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>cecily_lampkin</td>\n",
       "      <td>mg_advanced</td>\n",
       "      <td>funholding</td>\n",
       "      <td>2017-02-23</td>\n",
       "      <td>finance</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>united_states</td>\n",
       "      <td>dustin_brinkmann</td>\n",
       "      <td>central</td>\n",
       "      <td>8.885718</td>\n",
       "      <td>enterprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4026 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sales_agent         product     account engage_date     sector  \\\n",
       "1011    gladys_colclough          gtxpro    toughzap  2017-02-22     retail   \n",
       "5310     darcel_schlecht          gtxpro   streethex  2017-07-26     retail   \n",
       "3137     darcel_schlecht     mg_advanced    dontechi  2017-05-13   software   \n",
       "4546     kary_hendrixson          gtxpro    kan-code  2017-07-06   software   \n",
       "7122   marty_freudenburg          gtxpro   warephase  2017-09-30   services   \n",
       "...                  ...             ...         ...         ...        ...   \n",
       "98         corliss_cosme          gtxpro  betasoloin  2016-11-25    medical   \n",
       "2626  jonathan_berthelot      mg_special   streethex  2017-04-21     retail   \n",
       "372      kary_hendrixson       gtx_basic  goodsilron  2017-01-02  marketing   \n",
       "3994  jonathan_berthelot  gtx_plus_basic       isdom  2017-06-18    medical   \n",
       "1033      cecily_lampkin     mg_advanced  funholding  2017-02-23    finance   \n",
       "\n",
       "      year_established office_location           manager regional_office  \\\n",
       "1011            1995.0   united_states     melvin_marxen         central   \n",
       "5310            1988.0         belgium     melvin_marxen         central   \n",
       "3137            1982.0   united_states     melvin_marxen         central   \n",
       "4546            1982.0   united_states     summer_sewald            west   \n",
       "7122            1997.0   united_states     melvin_marxen         central   \n",
       "...                ...             ...               ...             ...   \n",
       "98              1999.0   united_states        cara_losch            east   \n",
       "2626            1988.0         belgium     melvin_marxen         central   \n",
       "372             2000.0   united_states     summer_sewald            west   \n",
       "3994            2002.0   united_states     melvin_marxen         central   \n",
       "1033            1991.0   united_states  dustin_brinkmann         central   \n",
       "\n",
       "      employees_log company_size  target  \n",
       "1011       6.684612       medium       0  \n",
       "5310       7.061334        large       1  \n",
       "3137       9.218705   enterprise       0  \n",
       "4546      10.442580         mega       0  \n",
       "7122       8.571113   enterprise       0  \n",
       "...             ...          ...     ...  \n",
       "98         6.206576       medium       0  \n",
       "2626       7.061334        large       0  \n",
       "372        8.538563   enterprise       0  \n",
       "3994       8.420903        large       0  \n",
       "1033       8.885718   enterprise       0  \n",
       "\n",
       "[4026 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.626428\n",
       "1    0.373572\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "10fb1136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.37357178340784897)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lost_rate = df_train.target.mean() \n",
    "lost_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sales_agent          object\n",
       "product              object\n",
       "account              object\n",
       "engage_date          object\n",
       "sector               object\n",
       "year_established    float64\n",
       "office_location      object\n",
       "manager              object\n",
       "regional_office      object\n",
       "employees_log       float64\n",
       "company_size         object\n",
       "target                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a390510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " FEATURE ENGINEERING\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" FEATURE ENGINEERING\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70815e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sales_agent',\n",
       " 'product',\n",
       " 'account',\n",
       " 'engage_date',\n",
       " 'sector',\n",
       " 'year_established',\n",
       " 'office_location',\n",
       " 'manager',\n",
       " 'regional_office',\n",
       " 'employees_log',\n",
       " 'company_size',\n",
       " 'target']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05a3d31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_agent</th>\n",
       "      <th>agent_lost_rate</th>\n",
       "      <th>agent_total_deals</th>\n",
       "      <th>agent_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anna_snelling</td>\n",
       "      <td>0.387255</td>\n",
       "      <td>204</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boris_faz</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cassey_cress</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>162</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cecily_lampkin</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>corliss_cosme</td>\n",
       "      <td>0.372414</td>\n",
       "      <td>145</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sales_agent  agent_lost_rate  agent_total_deals  agent_lost\n",
       "0   anna_snelling         0.387255                204          79\n",
       "1       boris_faz         0.333333                 90          30\n",
       "2    cassey_cress         0.382716                162          62\n",
       "3  cecily_lampkin         0.320000                100          32\n",
       "4   corliss_cosme         0.372414                145          54"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sales Agent Performance\n",
    "agent_stats = df_train.groupby('sales_agent').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "agent_stats.columns = ['sales_agent', 'agent_lost_rate', 'agent_total_deals', 'agent_lost']\n",
    "\n",
    "df_train = df_train.merge(agent_stats, on='sales_agent', how='left')\n",
    "df_val = df_val.merge(agent_stats, on='sales_agent', how='left')\n",
    "df_test = df_test.merge(agent_stats, on='sales_agent', how='left')\n",
    "df_active = df_active.merge(agent_stats, on='sales_agent', how='left')\n",
    "\n",
    "agent_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "975e7cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>account_lost_rate</th>\n",
       "      <th>account_deal_count</th>\n",
       "      <th>account_total_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acme_corporation</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>betasoloin</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>betatech</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>56</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bioholding</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bioplex</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            account  account_lost_rate  account_deal_count  account_total_lost\n",
       "0  acme_corporation           0.428571                  35                  15\n",
       "1        betasoloin           0.323529                  34                  11\n",
       "2          betatech           0.392857                  56                  22\n",
       "3        bioholding           0.333333                  42                  14\n",
       "4           bioplex           0.370370                  27                  10"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# account Performance\n",
    "account_stats = df_train.groupby('account').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "account_stats.columns = ['account', 'account_lost_rate', 'account_deal_count', 'account_total_lost']\n",
    "\n",
    "df_train = df_train.merge(account_stats, on='account', how='left')\n",
    "df_val = df_val.merge(account_stats, on='account', how='left')\n",
    "df_test = df_test.merge(account_stats, on='account', how='left')\n",
    "df_active = df_active.merge(account_stats, on='account', how='left')\n",
    "\n",
    "account_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aed0a82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sector</th>\n",
       "      <th>sector_lost_rate</th>\n",
       "      <th>sector_deal_count</th>\n",
       "      <th>sector_total_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>employment</td>\n",
       "      <td>0.352601</td>\n",
       "      <td>173</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>0.396694</td>\n",
       "      <td>242</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finance</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>378</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>marketing</td>\n",
       "      <td>0.365714</td>\n",
       "      <td>350</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medical</td>\n",
       "      <td>0.383821</td>\n",
       "      <td>581</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sector  sector_lost_rate  sector_deal_count  sector_total_lost\n",
       "0     employment          0.352601                173                 61\n",
       "1  entertainment          0.396694                242                 96\n",
       "2        finance          0.388889                378                147\n",
       "3      marketing          0.365714                350                128\n",
       "4        medical          0.383821                581                223"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sector Performance\n",
    "sector_stats = df_train.groupby('sector').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "sector_stats.columns = ['sector', 'sector_lost_rate', 'sector_deal_count', 'sector_total_lost']\n",
    "\n",
    "df_train = df_train.merge(sector_stats, on='sector', how='left')\n",
    "df_val = df_val.merge(sector_stats, on='sector', how='left')\n",
    "df_test = df_test.merge(sector_stats, on='sector', how='left')\n",
    "df_active = df_active.merge(sector_stats, on='sector', how='left')\n",
    "\n",
    "sector_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ad22e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>office_location</th>\n",
       "      <th>office_lost_rate</th>\n",
       "      <th>office_deal_count</th>\n",
       "      <th>office_total_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>belgium</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>64</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brazil</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>china</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>germany</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>italy</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  office_location  office_lost_rate  office_deal_count  office_total_lost\n",
       "0         belgium          0.328125                 64                 21\n",
       "1          brazil          0.321429                 28                  9\n",
       "2           china          0.240000                 25                  6\n",
       "3         germany          0.218750                 32                  7\n",
       "4           italy          0.408163                 49                 20"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Office Location Performance\n",
    "office_stats = df_train.groupby('office_location').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "office_stats.columns = ['office_location', 'office_lost_rate', 'office_deal_count', 'office_total_lost']\n",
    "\n",
    "df_train = df_train.merge(office_stats, on='office_location', how='left')\n",
    "df_val = df_val.merge(office_stats, on='office_location', how='left')\n",
    "df_test = df_test.merge(office_stats, on='office_location', how='left')\n",
    "df_active = df_active.merge(office_stats, on='office_location', how='left')\n",
    "\n",
    "office_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e44e6db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regional_office</th>\n",
       "      <th>region_lost_rate</th>\n",
       "      <th>region_deal_count</th>\n",
       "      <th>region_total_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>central</td>\n",
       "      <td>0.368926</td>\n",
       "      <td>1564</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>east</td>\n",
       "      <td>0.390917</td>\n",
       "      <td>1123</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>west</td>\n",
       "      <td>0.364451</td>\n",
       "      <td>1339</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  regional_office  region_lost_rate  region_deal_count  region_total_lost\n",
       "0         central          0.368926               1564                577\n",
       "1            east          0.390917               1123                439\n",
       "2            west          0.364451               1339                488"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regional Office Performance\n",
    "region_stats = df_train.groupby('regional_office').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "region_stats.columns = ['regional_office', 'region_lost_rate', 'region_deal_count', 'region_total_lost']\n",
    "\n",
    "df_train = df_train.merge(region_stats, on='regional_office', how='left')\n",
    "df_val = df_val.merge(region_stats, on='regional_office', how='left')\n",
    "df_test = df_test.merge(region_stats, on='regional_office', how='left')\n",
    "df_active = df_active.merge(region_stats, on='regional_office', how='left')\n",
    "\n",
    "region_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3b356ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_size_lost_rate</th>\n",
       "      <th>company_size_deal_count</th>\n",
       "      <th>company_size_total_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enterprise</td>\n",
       "      <td>0.365833</td>\n",
       "      <td>1159</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>large</td>\n",
       "      <td>0.372426</td>\n",
       "      <td>1748</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>medium</td>\n",
       "      <td>0.380556</td>\n",
       "      <td>360</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mega</td>\n",
       "      <td>0.404651</td>\n",
       "      <td>430</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>micro</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>104</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_size  company_size_lost_rate  company_size_deal_count  \\\n",
       "0   enterprise                0.365833                     1159   \n",
       "1        large                0.372426                     1748   \n",
       "2       medium                0.380556                      360   \n",
       "3         mega                0.404651                      430   \n",
       "4        micro                0.307692                      104   \n",
       "\n",
       "   company_size_total_lost  \n",
       "0                      424  \n",
       "1                      651  \n",
       "2                      137  \n",
       "3                      174  \n",
       "4                       32  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# company_size Performance\n",
    "company_size_stats = df_train.groupby('company_size').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "company_size_stats.columns = ['company_size', 'company_size_lost_rate', 'company_size_deal_count', 'company_size_total_lost']\n",
    "\n",
    "df_train = df_train.merge(company_size_stats, on='company_size', how='left')\n",
    "df_val = df_val.merge(company_size_stats, on='company_size', how='left')\n",
    "df_test = df_test.merge(company_size_stats, on='company_size', how='left')\n",
    "df_active = df_active.merge(company_size_stats, on='company_size', how='left')\n",
    "\n",
    "company_size_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d4e92a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>product_lost_rate</th>\n",
       "      <th>product_deal_count</th>\n",
       "      <th>product_total_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gtk_500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gtx_basic</td>\n",
       "      <td>0.361739</td>\n",
       "      <td>1150</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gtx_plus_basic</td>\n",
       "      <td>0.370595</td>\n",
       "      <td>823</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gtx_plus_pro</td>\n",
       "      <td>0.368249</td>\n",
       "      <td>611</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gtxpro</td>\n",
       "      <td>0.376392</td>\n",
       "      <td>898</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product  product_lost_rate  product_deal_count  product_total_lost\n",
       "0         gtk_500           0.500000                  18                   9\n",
       "1       gtx_basic           0.361739                1150                 416\n",
       "2  gtx_plus_basic           0.370595                 823                 305\n",
       "3    gtx_plus_pro           0.368249                 611                 225\n",
       "4          gtxpro           0.376392                 898                 338"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Product Performance\n",
    "product_stats = df_full_train.groupby('product').agg({\n",
    "    'target': ['mean', 'count', 'sum']\n",
    "}).reset_index()\n",
    "product_stats.columns = ['product', 'product_lost_rate', 'product_deal_count', 'product_total_lost']\n",
    "\n",
    "df_full_train = df_train.merge(product_stats, on='product', how='left')\n",
    "df_train = df_train.merge(product_stats, on='product', how='left')\n",
    "df_val = df_val.merge(product_stats, on='product', how='left')\n",
    "df_test = df_test.merge(product_stats, on='product', how='left')\n",
    "df_active = df_active.merge(product_stats, on='product', how='left')\n",
    "\n",
    "product_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de3abfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Aggregation features created:\n",
      "  - agent_lost_rate, agent_total_deals\n",
      "  - product_lost_rate, product_deal_count\n",
      "  - sector_lost_rate, sector_deal_count\n",
      "  - company_size_lost_rate, company_size_deal_count\n",
      "  - region_lost_rate, region_deal_count\n"
     ]
    }
   ],
   "source": [
    "print(\"✓ Aggregation features created:\")\n",
    "print(f\"  - agent_lost_rate, agent_total_deals\")\n",
    "print(f\"  - product_lost_rate, product_deal_count\")\n",
    "print(f\"  - sector_lost_rate, sector_deal_count\")\n",
    "print(f\"  - company_size_lost_rate, company_size_deal_count\")\n",
    "print(f\"  - region_lost_rate, region_deal_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e331b19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.1: Extracting Temporal Features...\n",
      "✓ Temporal features created: month, quarter, day_of_week, is_weekend, days_into_year\n"
     ]
    }
   ],
   "source": [
    "# -------- 5.1: TEMPORAL FEATURES FROM ENGAGE_DATE --------\n",
    "print(\"\\n5.1: Extracting Temporal Features...\")\n",
    "\n",
    "# Convert to datetime\n",
    "\n",
    "df_train['engage_date'] = pd.to_datetime(df_train['engage_date'])\n",
    "df_val['engage_date'] = pd.to_datetime(df_val['engage_date'])\n",
    "df_test['engage_date'] = pd.to_datetime(df_test['engage_date'])\n",
    "df_active['engage_date'] = pd.to_datetime(df_active['engage_date'])\n",
    "\n",
    "\n",
    "# Extract temporal features\n",
    "df_train['month_engaged'] = df_train['engage_date'].dt.month\n",
    "df_train['quarter_engaged'] = df_train['engage_date'].dt.quarter\n",
    "df_train['day_of_week_engaged'] = df_train['engage_date'].dt.dayofweek\n",
    "df_train['is_weekend'] = (df_train['day_of_week_engaged'].isin([5, 6])).astype(int)\n",
    "df_train['days_into_year'] = df_train['engage_date'].dt.dayofyear\n",
    "\n",
    "# Extract temporal features\n",
    "df_val['month_engaged'] = df_val['engage_date'].dt.month\n",
    "df_val['quarter_engaged'] = df_val['engage_date'].dt.quarter\n",
    "df_val['day_of_week_engaged'] = df_val['engage_date'].dt.dayofweek\n",
    "df_val['is_weekend'] = (df_val['day_of_week_engaged'].isin([5, 6])).astype(int)\n",
    "df_val['days_into_year'] = df_val['engage_date'].dt.dayofyear\n",
    "\n",
    "# Extract temporal features\n",
    "df_test['month_engaged'] = df_test['engage_date'].dt.month\n",
    "df_test['quarter_engaged'] = df_test['engage_date'].dt.quarter\n",
    "df_test['day_of_week_engaged'] = df_test['engage_date'].dt.dayofweek\n",
    "df_test['is_weekend'] = (df_test['day_of_week_engaged'].isin([5, 6])).astype(int)\n",
    "df_test['days_into_year'] = df_test['engage_date'].dt.dayofyear\n",
    "\n",
    "# Apply same to active deals\n",
    "df_active['month_engaged'] = df_active['engage_date'].dt.month\n",
    "df_active['quarter_engaged'] = df_active['engage_date'].dt.quarter\n",
    "df_active['day_of_week_engaged'] = df_active['engage_date'].dt.dayofweek\n",
    "df_active['is_weekend'] = (df_active['day_of_week_engaged'].isin([5, 6])).astype(int)\n",
    "df_active['days_into_year'] = df_active['engage_date'].dt.dayofyear\n",
    "\n",
    "print(\"✓ Temporal features created: month, quarter, day_of_week, is_weekend, days_into_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9781a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5.2: Calculating Deal Duration...\n",
      "  Reference date: 2017-12-31\n"
     ]
    }
   ],
   "source": [
    "# -------- 5.2: DEAL DURATION --------\n",
    "print(\"\\n5.2: Calculating Deal Duration...\")\n",
    "\n",
    "# Convert to datetime\n",
    "df['engage_date'] = pd.to_datetime(df['engage_date'])\n",
    "df['close_date'] = pd.to_datetime(df['close_date'], errors='coerce')\n",
    "\n",
    "# Get reference date as the max date in dataset\n",
    "ref_date = df[['engage_date', 'close_date']].max().max()\n",
    "print(f\"  Reference date: {ref_date.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0536d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Deal age calculated\n",
      "  Average: 97 days\n",
      "  Min-Max: 1 - 423 days\n"
     ]
    }
   ],
   "source": [
    "# Calculate deal duration\n",
    "df['closed_duration'] = (df['close_date'] - df['engage_date']).dt.days\n",
    "df['active_duration'] = (ref_date - df['engage_date']).dt.days\n",
    "df['deal_age'] = df['closed_duration'].fillna(df['active_duration'])\n",
    "\n",
    "# Apply to training and active data\n",
    "\n",
    "df_train['deal_age'] = df.loc[df_train.index, 'deal_age'].values\n",
    "df_val['deal_age'] = df.loc[df_val.index, 'deal_age'].values\n",
    "df_test['deal_age'] = df.loc[df_test.index, 'deal_age'].values\n",
    "df_active['deal_age'] = df.loc[df_active.index, 'deal_age'].values\n",
    "\n",
    "print(f\"✓ Deal age calculated\")\n",
    "print(f\"  Average: {df_train['deal_age'].mean():.0f} days\")\n",
    "print(f\"  Min-Max: {df_train['deal_age'].min():.0f} - {df_train['deal_age'].max():.0f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c454f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " RELATIVE RATIO\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" RELATIVE RATIO\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4026, 39)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f45930da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Interaction Features...\n"
     ]
    }
   ],
   "source": [
    "# --------  INTERACTION FEATURES --------\n",
    "print(\"\\nCreating Interaction Features...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "784626f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Interaction features created:\n",
      "  - product_sector\n",
      "  - company_size_region\n",
      "  - agent_product_expertise\n",
      "  - duration_per_employee\n",
      "  - duration_norm\n"
     ]
    }
   ],
   "source": [
    "# Product-Sector Interaction\n",
    "\n",
    "df_train['product_sector'] = df_train['product'] + '_' + df_train['sector']\n",
    "df_val['product_sector'] = df_val['product'] + '_' + df_val['sector']\n",
    "df_test['product_sector'] = df_test['product'] + '_' + df_test['sector']\n",
    "df_active['product_sector'] = df_active['product'] + '_' + df_active['sector']\n",
    "\n",
    "# company_size_region-Region Interaction\n",
    "\n",
    "df_train['company_size_region'] = df_train['company_size'] + '_' + df_train['regional_office']\n",
    "df_val['company_size_region'] = df_val['company_size'] + '_' + df_val['regional_office']\n",
    "df_test['company_size_region'] = df_test['company_size'] + '_' + df_test['regional_office']\n",
    "df_active['company_size_region'] = df_active['company_size'] + '_' + df_active['regional_office']\n",
    "\n",
    "# Agent expertise (win_rate × product performance)\n",
    "\n",
    "df_train['agent_product_expertise'] = df_train['agent_lost_rate'] * df_train['product_lost_rate']\n",
    "df_val['agent_product_expertise'] = df_val['agent_lost_rate'] * df_val['product_lost_rate']\n",
    "df_test['agent_product_expertise'] = df_test['agent_lost_rate'] * df_test['product_lost_rate']\n",
    "df_active['agent_product_expertise'] = df_active['agent_lost_rate'] * df_active['product_lost_rate']\n",
    "\n",
    "#duration_per_employee\n",
    "\n",
    "df_train['duration_per_employee'] = df_train['deal_age'] / df_train['employees_log'].replace(0, 1)\n",
    "df_val['duration_per_employee'] = df_val['deal_age'] / df_val['employees_log'].replace(0, 1)\n",
    "df_test['duration_per_employee'] = df_test['deal_age'] / df_test['employees_log'].replace(0, 1)\n",
    "df_active['duration_per_employee'] = df_active['deal_age'] / df_active['employees_log'].replace(0, 1)\n",
    "\n",
    "#duration_norm\n",
    "\n",
    "df_train['duration_norm'] = df_train['deal_age'] / df_train.groupby('sector')['deal_age'].transform('mean')\n",
    "df_val['duration_norm'] = df_val['deal_age'] / df_val.groupby('sector')['deal_age'].transform('mean')\n",
    "df_test['duration_norm'] = df_test['deal_age'] / df_test.groupby('sector')['deal_age'].transform('mean')\n",
    "df_active['duration_norm'] = df_active['deal_age'] / df_active.groupby('sector')['deal_age'].transform('mean')\n",
    "\n",
    "print(\"✓ Interaction features created:\")\n",
    "print(f\"  - product_sector\")\n",
    "print(f\"  - company_size_region\")\n",
    "print(f\"  - agent_product_expertise\")\n",
    "print(f\"  - duration_per_employee\")\n",
    "print(f\"  - duration_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eec05847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ADVANCED FEATURE ENGINEERING - ROC-AUC OPTIMIZATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ADVANCED FEATURE ENGINEERING - ROC-AUC OPTIMIZATION\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "658879e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['sales_agent','product','account', 'sector','office_location','manager','regional_office','company_size','product_sector', 'company_size_region'\n",
    "               ]\n",
    "numerical = ['year_established',\n",
    "             'employees_log',\n",
    "             'agent_lost_rate',\n",
    "             'agent_total_deals',\n",
    "             'agent_lost',\n",
    "             'account_lost_rate',\n",
    "             'account_deal_count',\n",
    "             'account_total_lost',\n",
    "             'sector_lost_rate','office_lost_rate',\n",
    "             'office_deal_count', \n",
    "             'office_total_lost',\n",
    "             'region_lost_rate',\n",
    "             'region_deal_count', \n",
    "       'region_total_lost', \n",
    "       'company_size_lost_rate',\n",
    "       'company_size_deal_count', \n",
    "       'company_size_total_lost', \n",
    "       'product_lost_rate',\n",
    "       'product_deal_count', \n",
    "       'product_total_lost', \n",
    "       'month_engaged',\n",
    "       'quarter_engaged', \n",
    "       'day_of_week_engaged',\n",
    "       'is_weekend',\n",
    "       'days_into_year', \n",
    "       'deal_age',\n",
    "       'agent_product_expertise',\n",
    "       'duration_per_employee',\n",
    "       'duration_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6ae19e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Applying Target Encoding for Categorical Features...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "categorical = ['sales_agent', 'product', 'account', 'sector', \n",
    "               'office_location', 'manager', 'regional_office', \n",
    "               'company_size', 'product_sector', 'company_size_region']\n",
    "\n",
    "print(\"\\n1. Applying Target Encoding for Categorical Features...\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a08aaf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use smoothing to prevent overfitting\n",
    "encoder = TargetEncoder(cols=categorical, smoothing=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "60338db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Encoded 10 categorical features\n"
     ]
    }
   ],
   "source": [
    "# Fit on train, transform both\n",
    "df_train_encoded = encoder.fit_transform(df_train[categorical], y_train)\n",
    "df_val_encoded = encoder.transform(df_val[categorical])\n",
    "\n",
    "print(f\"✓ Encoded {len(categorical)} categorical features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93a1e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Creating Advanced Interaction Features...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. Creating Advanced Interaction Features...\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5330215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created 9 advanced interaction features\n"
     ]
    }
   ],
   "source": [
    "# Agent-Product performance synergy\n",
    "df_train['agent_product_synergy'] = df_train['agent_lost_rate'] * df_train['product_lost_rate']\n",
    "df_val['agent_product_synergy'] = df_val['agent_lost_rate'] * df_val['product_lost_rate']\n",
    "\n",
    "# Agent efficiency metrics\n",
    "df_train['agent_win_efficiency'] = (1 - df_train['agent_lost_rate']) * df_train['agent_total_deals']\n",
    "df_val['agent_win_efficiency'] = (1 - df_val['agent_lost_rate']) * df_val['agent_total_deals']\n",
    "\n",
    "# Performance relative to sector\n",
    "df_train['agent_vs_sector'] = df_train['agent_lost_rate'] - df_train['sector_lost_rate']\n",
    "df_val['agent_vs_sector'] = df_val['agent_lost_rate'] - df_val['sector_lost_rate']\n",
    "\n",
    "# Deal complexity score\n",
    "df_train['deal_complexity'] = (\n",
    "    df_train['employees_log'] * df_train['deal_age'] / \n",
    "    (df_train['agent_total_deals'] + 1)\n",
    ")\n",
    "df_val['deal_complexity'] = (\n",
    "    df_val['employees_log'] * df_val['deal_age'] / \n",
    "    (df_val['agent_total_deals'] + 1)\n",
    ")\n",
    "\n",
    "# Office load vs performance\n",
    "df_train['office_load'] = df_train['office_deal_count'] / (df_train['office_total_lost'] + 1)\n",
    "df_val['office_load'] = df_val['office_deal_count'] / (df_val['office_total_lost'] + 1)\n",
    "\n",
    "# Product-sector fit\n",
    "df_train['product_sector_fit'] = df_train['product_lost_rate'] * df_train['sector_lost_rate']\n",
    "df_val['product_sector_fit'] = df_val['product_lost_rate'] * df_val['sector_lost_rate']\n",
    "\n",
    "# Regional performance relative to company size\n",
    "df_train['region_size_match'] = df_train['region_lost_rate'] * df_train['company_size_lost_rate']\n",
    "df_val['region_size_match'] = df_val['region_lost_rate'] * df_val['company_size_lost_rate']\n",
    "\n",
    "# Temporal risk factors\n",
    "df_train['quarter_risk'] = df_train['quarter_engaged'].map({1: 0.8, 2: 0.9, 3: 1.0, 4: 1.2})\n",
    "df_val['quarter_risk'] = df_val['quarter_engaged'].map({1: 0.8, 2: 0.9, 3: 1.0, 4: 1.2})\n",
    "\n",
    "df_train['is_quarter_end'] = df_train['month_engaged'].isin([3, 6, 9, 12]).astype(int)\n",
    "df_val['is_quarter_end'] = df_val['month_engaged'].isin([3, 6, 9, 12]).astype(int)\n",
    "\n",
    "print(\"✓ Created 9 advanced interaction features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40a64faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Total numerical features: 39\n"
     ]
    }
   ],
   "source": [
    "numerical_advanced = numerical + [\n",
    "    'agent_product_synergy',\n",
    "    'agent_win_efficiency', \n",
    "    'agent_vs_sector',\n",
    "    'deal_complexity',\n",
    "    'office_load',\n",
    "    'product_sector_fit',\n",
    "    'region_size_match',\n",
    "    'quarter_risk',\n",
    "    'is_quarter_end'\n",
    "]\n",
    "\n",
    "print(f\"\\n✓ Total numerical features: {len(numerical_advanced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dabe034c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Combining Features...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3. Combining Features...\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training shape: (4026, 49)\n",
      "✓ Validation shape: (1342, 49)\n"
     ]
    }
   ],
   "source": [
    "# Combine target-encoded categoricals with numerical features\n",
    "X_train_combined = pd.concat([\n",
    "    df_train_encoded,\n",
    "    df_train[numerical_advanced]\n",
    "], axis=1)\n",
    "\n",
    "X_val_combined = pd.concat([\n",
    "    df_val_encoded,\n",
    "    df_val[numerical_advanced]\n",
    "], axis=1)\n",
    "\n",
    "# Handle any missing values\n",
    "X_train_combined = X_train_combined.fillna(X_train_combined.median())\n",
    "X_val_combined = X_val_combined.fillna(X_train_combined.median())\n",
    "\n",
    "print(f\"✓ Training shape: {X_train_combined.shape}\")\n",
    "print(f\"✓ Validation shape: {X_val_combined.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "71d04c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Scaling Features...\n",
      "--------------------------------------------------\n",
      "✓ Features scaled\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4. Scaling Features...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "X_val_scaled = scaler.transform(X_val_combined)\n",
    "\n",
    "print(\"✓ Features scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Applying SMOTE Resampling...\n",
      "--------------------------------------------------\n",
      "Before SMOTE: [2522 1504]\n",
      "After SMOTE:  [2522 1765]\n",
      "✓ Training set size: 4287\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5. Applying SMOTE Resampling...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "print(f\"Before SMOTE: {np.bincount(y_train)}\")\n",
    "\n",
    "smote = BorderlineSMOTE(\n",
    "    sampling_strategy=0.7,  # Make lost class 70% of won class\n",
    "    random_state=42,\n",
    "    k_neighbors=5\n",
    ")\n",
    "\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"After SMOTE:  {np.bincount(y_train_resampled)}\")\n",
    "print(f\"✓ Training set size: {len(X_train_resampled)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " FEATURE IMPORTANCE: CORRELATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" FEATURE IMPORTANCE: CORRELATION\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9a1d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the target variable from the feature DataFrames\n",
    "del df_train['target']\n",
    "del df_val['target']\n",
    "del df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d8265f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING OPTIMIZED MODELS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING OPTIMIZED MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models_optimized = {}\n",
    "results_optimized = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Training Optimized XGBoost...\n",
      "--------------------------------------------------\n",
      "✓ XGBoost trained\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1: Optimized XGBoost\n",
    "print(\"\\n1. Training Optimized XGBoost...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "xgb_opt = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.03,\n",
    "    min_child_weight=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.7,\n",
    "    gamma=0.2,\n",
    "    scale_pos_weight=3,  # For class imbalance\n",
    "    reg_alpha=1,\n",
    "    reg_lambda=2,\n",
    "    random_state=42,\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=50,\n",
    "    verbosity=0\n",
    ")\n",
    "xgb_opt.fit(\n",
    "    X_train_resampled, \n",
    "    y_train_resampled,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "y_pred_xgb = xgb_opt.predict(X_val_scaled)\n",
    "y_proba_xgb = xgb_opt.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "models_optimized['XGBoost'] = xgb_opt\n",
    "results_optimized['XGBoost'] = {\n",
    "    'predictions': y_pred_xgb,\n",
    "    'probabilities': y_proba_xgb\n",
    "}\n",
    "\n",
    "print(\"✓ XGBoost trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Training LightGBM...\n",
      "--------------------------------------------------\n",
      "✓ LightGBM trained\n"
     ]
    }
   ],
   "source": [
    "# MODEL 2: LightGBM (often performs better on imbalanced data)\n",
    "print(\"\\n2. Training LightGBM...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "lgbm_opt = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=30,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.7,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "lgbm_opt.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_lgbm = lgbm_opt.predict(X_val_scaled)\n",
    "y_proba_lgbm = lgbm_opt.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "models_optimized['LightGBM'] = lgbm_opt\n",
    "results_optimized['LightGBM'] = {\n",
    "    'predictions': y_pred_lgbm,\n",
    "    'probabilities': y_proba_lgbm\n",
    "}\n",
    "\n",
    "print(\"✓ LightGBM trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Training Optimized Gradient Boosting...\n",
      "--------------------------------------------------\n",
      "✓ Gradient Boosting trained\n"
     ]
    }
   ],
   "source": [
    "# MODEL 3: Optimized Gradient Boosting\n",
    "print(\"\\n3. Training Optimized Gradient Boosting...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "gb_opt = GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    subsample=0.8,\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gb_opt.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_gb = gb_opt.predict(X_val_scaled)\n",
    "y_proba_gb = gb_opt.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "models_optimized['GradientBoosting'] = gb_opt\n",
    "results_optimized['GradientBoosting'] = {\n",
    "    'predictions': y_pred_gb,\n",
    "    'probabilities': y_proba_gb\n",
    "}\n",
    "\n",
    "print(\"✓ Gradient Boosting trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Training Optimized Logistic Regression...\n",
      "--------------------------------------------------\n",
      "✓ Logistic Regression trained\n"
     ]
    }
   ],
   "source": [
    "# MODEL 4: Optimized Logistic Regression\n",
    "print(\"\\n4. Training Optimized Logistic Regression...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "lr_opt = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    C=0.1,\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    solver='saga',\n",
    "    penalty='elasticnet',\n",
    "    l1_ratio=0.5\n",
    ")\n",
    "\n",
    "lr_opt.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred_lr = lr_opt.predict(X_val_scaled)\n",
    "y_proba_lr = lr_opt.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "models_optimized['LogisticRegression'] = lr_opt\n",
    "results_optimized['LogisticRegression'] = {\n",
    "    'predictions': y_pred_lr,\n",
    "    'probabilities': y_proba_lr\n",
    "}\n",
    "\n",
    "print(\"✓ Logistic Regression trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL EVALUATION - OPTIMIZED MODELS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL EVALUATION - OPTIMIZED MODELS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f867afcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.4195\n",
      "ROC-AUC:    0.5397  ← MAIN METRIC\n",
      "Precision:  0.3833\n",
      "Recall:     0.9316\n",
      "F1-Score:   0.5431\n",
      "\n",
      "LightGBM\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.5589\n",
      "ROC-AUC:    0.5294  ← MAIN METRIC\n",
      "Precision:  0.4017\n",
      "Recall:     0.3903\n",
      "F1-Score:   0.3959\n",
      "\n",
      "GradientBoosting\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.5842\n",
      "ROC-AUC:    0.5293  ← MAIN METRIC\n",
      "Precision:  0.4026\n",
      "Recall:     0.2535\n",
      "F1-Score:   0.3111\n",
      "\n",
      "LogisticRegression\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.5089\n",
      "ROC-AUC:    0.5195  ← MAIN METRIC\n",
      "Precision:  0.3726\n",
      "Recall:     0.4769\n",
      "F1-Score:   0.4184\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = []\n",
    "\n",
    "for model_name, results in results_optimized.items():\n",
    "    y_pred = results['predictions']\n",
    "    y_proba = results['probabilities']\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_proba)\n",
    "    precision = precision_score(y_val, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_val, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "    \n",
    "    evaluation_results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Accuracy:   {accuracy:.4f}\")\n",
    "    print(f\"ROC-AUC:    {roc_auc:.4f}  ← MAIN METRIC\")\n",
    "    print(f\"Precision:  {precision:.4f}\")\n",
    "    print(f\"Recall:     {recall:.4f}\")\n",
    "    print(f\"F1-Score:   {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68bc3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "eval_comparison = pd.DataFrame(evaluation_results)\n",
    "eval_comparison = eval_comparison.sort_values('ROC-AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ff297d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON (Sorted by ROC-AUC)\n",
      "================================================================================\n",
      "             Model  Accuracy  ROC-AUC  Precision   Recall  F1-Score\n",
      "           XGBoost  0.419523 0.539725   0.383278 0.931590  0.543109\n",
      "          LightGBM  0.558867 0.529442   0.401656 0.390342  0.395918\n",
      "  GradientBoosting  0.584203 0.529289   0.402556 0.253521  0.311111\n",
      "LogisticRegression  0.508942 0.519546   0.372642 0.476861  0.418358\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON (Sorted by ROC-AUC)\")\n",
    "print(\"=\"*80)\n",
    "print(eval_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ENSEMBLE PREDICTION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENSEMBLE PREDICTION\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29edf590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average predictions from top 3 models\n",
    "top_3_models = eval_comparison.head(3)['Model'].tolist()\n",
    "\n",
    "ensemble_proba = np.mean([\n",
    "    results_optimized[model]['probabilities'] \n",
    "    for model in top_3_models\n",
    "], axis=0)\n",
    "\n",
    "ensemble_pred = (ensemble_proba >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3a2d44ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble of: XGBoost, LightGBM, GradientBoosting\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.5343\n",
      "ROC-AUC:    0.5331  ← ENSEMBLE SCORE\n",
      "Precision:  0.3930\n",
      "Recall:     0.4728\n",
      "F1-Score:   0.4292\n"
     ]
    }
   ],
   "source": [
    "# Evaluate ensemble\n",
    "ensemble_roc_auc = roc_auc_score(y_val, ensemble_proba)\n",
    "ensemble_accuracy = accuracy_score(y_val, ensemble_pred)\n",
    "ensemble_precision = precision_score(y_val, ensemble_pred, zero_division=0)\n",
    "ensemble_recall = recall_score(y_val, ensemble_pred, zero_division=0)\n",
    "ensemble_f1 = f1_score(y_val, ensemble_pred, zero_division=0)\n",
    "\n",
    "print(f\"\\nEnsemble of: {', '.join(top_3_models)}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Accuracy:   {ensemble_accuracy:.4f}\")\n",
    "print(f\"ROC-AUC:    {ensemble_roc_auc:.4f}  ← ENSEMBLE SCORE\")\n",
    "print(f\"Precision:  {ensemble_precision:.4f}\")\n",
    "print(f\"Recall:     {ensemble_recall:.4f}\")\n",
    "print(f\"F1-Score:   {ensemble_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TOP 20 MOST IMPORTANT FEATURES\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 20 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 features from XGBoost:\n",
      "--------------------------------------------------\n",
      "                feature  importance\n",
      "         is_quarter_end    0.044053\n",
      "           quarter_risk    0.037409\n",
      "        quarter_engaged    0.032344\n",
      "          month_engaged    0.031772\n",
      "                account    0.029425\n",
      "         product_sector    0.029131\n",
      "  agent_product_synergy    0.028894\n",
      "      account_lost_rate    0.027986\n",
      "         days_into_year    0.023786\n",
      "agent_product_expertise    0.023667\n",
      "      office_deal_count    0.023115\n",
      "    day_of_week_engaged    0.021546\n",
      "        agent_lost_rate    0.021448\n",
      "            sales_agent    0.020721\n",
      "        regional_office    0.020657\n",
      "       region_lost_rate    0.020310\n",
      "      office_total_lost    0.020221\n",
      "       office_lost_rate    0.019625\n",
      "      agent_total_deals    0.019387\n",
      "             agent_lost    0.019374\n",
      "\n",
      "================================================================================\n",
      "OPTIMIZATION COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "✓ Original ROC-AUC: ~0.55\n",
      "✓ Optimized ROC-AUC: 0.5397\n",
      "✓ Ensemble ROC-AUC: 0.5331\n",
      "\n",
      "🎯 Expected ROC-AUC improvement: 0.10-0.20 points\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance from best model\n",
    "best_model_name = eval_comparison.iloc[0]['Model']\n",
    "best_model = models_optimized[best_model_name]\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train_combined.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 20 features from {best_model_name}:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n✓ Original ROC-AUC: ~0.55\")\n",
    "print(f\"✓ Optimized ROC-AUC: {eval_comparison.iloc[0]['ROC-AUC']:.4f}\")\n",
    "print(f\"✓ Ensemble ROC-AUC: {ensemble_roc_auc:.4f}\")\n",
    "print(f\"\\n🎯 Expected ROC-AUC improvement: 0.10-0.20 points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "40468c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAIN 4 MODELS WITH REGULARIZATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAIN 4 MODELS WITH REGULARIZATION\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106a751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b8e3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9237c968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. LOGISTIC REGRESSION (with L2 Regularization)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store models and results\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# -------- MODEL 1: LOGISTIC REGRESSION --------\n",
    "print(\"\\n1. LOGISTIC REGRESSION (with L2 Regularization)\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8ac0634e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m lr_model \u001b[38;5;241m=\u001b[39m LogisticRegression(\n\u001b[0;32m      2\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      3\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, \n\u001b[0;32m      4\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m      5\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m      6\u001b[0m     )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m lr_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ Model trained\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(\n",
    "    class_weight='balanced', \n",
    "    max_iter=1000, \n",
    "    random_state=42,\n",
    "    C=0.1\n",
    "    )\n",
    "\n",
    "# Train\n",
    "lr_model.fit(X_train, y_train)\n",
    "print(\"✓ Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009e5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.001, -0.002,  0.001,  0.   , -0.001,  0.001,  0.001, -0.   ,\n",
       "        0.   , -0.   ,  0.   ,  0.002,  0.   , -0.001,  0.   , -0.001,\n",
       "       -0.   , -0.   , -0.001,  0.001,  0.001,  0.   , -0.   , -0.   ,\n",
       "       -0.001,  0.001, -0.001,  0.001,  0.001, -0.   ,  0.002, -0.001,\n",
       "        0.001,  0.002,  0.   , -0.005,  0.   , -0.002, -0.001, -0.001,\n",
       "       -0.001,  0.002, -0.001,  0.002, -0.001,  0.001,  0.002,  0.002,\n",
       "        0.001, -0.   , -0.002, -0.   , -0.001, -0.001, -0.   , -0.   ,\n",
       "        0.001,  0.001, -0.001, -0.001,  0.001,  0.001,  0.001, -0.   ,\n",
       "       -0.001, -0.001,  0.   ,  0.001,  0.001,  0.   ,  0.001,  0.001,\n",
       "       -0.   , -0.   , -0.   , -0.001,  0.001,  0.002, -0.001, -0.001,\n",
       "        0.   , -0.002, -0.002, -0.002, -0.   , -0.032,  0.004,  0.087,\n",
       "        0.03 ,  0.001,  0.001, -0.011, -0.002,  0.002, -0.001, -0.   ,\n",
       "        0.002, -0.001,  0.001, -0.   , -0.005,  0.001,  0.002,  0.001,\n",
       "       -0.001,  0.002,  0.001, -0.001, -0.001,  0.001,  0.   , -0.001,\n",
       "        0.002,  0.003, -0.002,  0.001, -0.002,  0.   , -0.002, -0.04 ,\n",
       "       -0.001, -0.   , -0.   ,  0.002, -0.015, -0.003,  0.002, -0.   ,\n",
       "        0.   ,  0.   , -0.002,  0.   ,  0.011,  0.012,  0.001, -0.   ,\n",
       "       -0.002, -0.002,  0.001,  0.001,  0.001,  0.001, -0.005,  0.001,\n",
       "        0.001,  0.   ,  0.   ,  0.001,  0.   ,  0.   , -0.032,  0.003,\n",
       "       -0.001,  0.   , -0.009,  0.003,  0.001,  0.003, -0.002,  0.   ,\n",
       "       -0.   ,  0.001,  0.   ,  0.001,  0.   ,  0.001,  0.001, -0.002,\n",
       "       -0.003, -0.002, -0.002,  0.006, -0.012,  0.002, -0.001,  0.008,\n",
       "        0.006,  0.002,  0.002,  0.   ,  0.001, -0.003, -0.002,  0.   ,\n",
       "        0.003, -0.003, -0.001, -0.002, -0.001,  0.001,  0.004, -0.002,\n",
       "        0.004, -0.001, -0.005, -0.003, -0.004,  0.003,  0.003,  0.   ,\n",
       "       -0.003, -0.001,  0.001, -0.001,  0.002, -0.006,  0.003, -0.001,\n",
       "       -0.004, -0.   , -0.002,  0.003,  0.001, -0.001,  0.001,  0.002,\n",
       "        0.001, -0.002,  0.002, -0.   ,  0.   ,  0.002,  0.013, -0.   ,\n",
       "       -0.002, -0.001, -0.007,  0.005,  0.048,  0.001, -0.   , -0.001,\n",
       "        0.   , -0.   , -0.   , -0.001, -0.001, -0.   , -0.002,  0.001,\n",
       "        0.001, -0.001, -0.002,  0.001,  0.001,  0.   , -0.003, -0.001,\n",
       "        0.001,  0.002, -0.002, -0.   ,  0.001, -0.001, -0.   ,  0.   ,\n",
       "        0.001, -0.   ,  0.001,  0.002,  0.003,  0.   ,  0.003, -0.005,\n",
       "        0.002, -0.001, -0.   , -0.001, -0.001,  0.005,  0.006, -0.002,\n",
       "       -0.002, -0.003,  0.   ,  0.   , -0.   ])"
      ]
     },
     "execution_count": 2659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.coef_[0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_tr_pred_lr = lr_model.predict(X_train)\n",
    "y_te_pred_lr = lr_model.predict(X_val)\n",
    "y_te_proba_lr = lr_model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions generated\n"
     ]
    }
   ],
   "source": [
    "# Store\n",
    "models['Logistic Regression'] = lr_model\n",
    "results['Logistic Regression'] = {\n",
    "    'train_pred': y_tr_pred_lr,\n",
    "    'val_pred': y_te_pred_lr,\n",
    "    'val_proba': y_te_proba_lr,\n",
    "    'feature_importance': np.abs(lr_model.coef_[0])\n",
    "}\n",
    "\n",
    "print(\"✓ Predictions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8796988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. RANDOM FOREST (with Regularization Parameters)\n",
      "--------------------------------------------------\n",
      "✓ Model trained\n"
     ]
    }
   ],
   "source": [
    "# -------- MODEL 2: RANDOM FOREST --------\n",
    "print(\"\\n2. RANDOM FOREST (with Regularization Parameters)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    class_weight='balanced', \n",
    "    random_state=42,\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20\n",
    "    )\n",
    "\n",
    "# Train\n",
    "rf_model.fit(X_train, y_train)  # Note: RF doesn't need scaling\n",
    "print(\"✓ Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9449f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_tr_pred_rf = rf_model.predict(X_train)\n",
    "y_te_pred_rf = rf_model.predict(X_val)\n",
    "y_te_proba_rf = rf_model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a5bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions generated\n"
     ]
    }
   ],
   "source": [
    "# Store\n",
    "models['Random Forest'] = rf_model\n",
    "results['Random Forest'] = {\n",
    "    'train_pred': y_tr_pred_rf,\n",
    "    'val_pred': y_te_pred_rf,\n",
    "    'val_proba': y_te_proba_rf,\n",
    "    'feature_importance': rf_model.feature_importances_\n",
    "}\n",
    "\n",
    "print(\"✓ Predictions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. GRADIENT BOOSTING (with Regularization)\n",
      "--------------------------------------------------\n",
      "✓ Model trained\n"
     ]
    }
   ],
   "source": [
    "# -------- MODEL 3: GRADIENT BOOSTING (XGBoost style) --------\n",
    "print(\"\\n3. GRADIENT BOOSTING (with Regularization)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,           # Number of boosting stages\n",
    "    learning_rate=0.1,          # Step size shrinkage\n",
    "    max_depth=5,                # Max depth of each tree\n",
    "    min_samples_leaf=5,         # Minimum samples in leaf\n",
    "    min_samples_split=10,\n",
    "    subsample=0.8,              # Fraction of samples for fitting each tree\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Train\n",
    "gb_model.fit(X_train, y_train)  # Boosting doesn't need scaling\n",
    "print(\"✓ Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_tr_pred_gb = gb_model.predict(X_train)\n",
    "y_te_pred_gb = gb_model.predict(X_val)\n",
    "y_te_proba_gb = gb_model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c26484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions generated\n"
     ]
    }
   ],
   "source": [
    "# Store\n",
    "models['Gradient Boosting'] = gb_model\n",
    "results['Gradient Boosting'] = {\n",
    "    'train_pred': y_tr_pred_gb,\n",
    "    'val_pred': y_te_pred_gb,\n",
    "    'val_proba': y_te_proba_gb,\n",
    "    'feature_importance': gb_model.feature_importances_\n",
    "}\n",
    "\n",
    "print(\"✓ Predictions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607afdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. XGRADIENT BOOSTING (with Regularization)\n",
      "--------------------------------------------------\n",
      "✓ Model trained\n"
     ]
    }
   ],
   "source": [
    "# -------- MODEL 3: GRADIENT BOOSTING (XGBoost style) --------\n",
    "print(\"\\n3. XGRADIENT BOOSTING (with Regularization)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    scale_pos_weight=3, \n",
    "    random_state=42)\n",
    "\n",
    "\n",
    "# Train\n",
    "xgb_model.fit(X_train, y_train)  # Boosting doesn't need scaling\n",
    "print(\"✓ Model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a6f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_tr_pred_xgb = xgb_model.predict(X_train)\n",
    "y_te_pred_xgb = xgb_model.predict(X_val)\n",
    "y_te_proba_xgb = xgb_model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d008bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions generated\n"
     ]
    }
   ],
   "source": [
    "# Store\n",
    "models['XGradient Boosting'] = xgb_model\n",
    "results['XGradient Boosting'] = {\n",
    "    'train_pred': y_tr_pred_xgb,\n",
    "    'val_pred': y_te_pred_xgb,\n",
    "    'val_proba': y_te_proba_xgb,\n",
    "    'feature_importance': xgb_model.feature_importances_\n",
    "}\n",
    "\n",
    "print(\"✓ Predictions generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL EVALUATION\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation dataframe\n",
    "evaluation_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e5d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.5075 (Higher is better)\n",
      "ROC-AUC:    0.5032 (Higher is better | 1.0 = Perfect)\n",
      "Precision:  0.3727 (Of predicted wins, how many correct?)\n",
      "Recall:     0.4829 (Of actual wins, how many caught?)\n",
      "F1-Score:   0.4207 (Balance between precision & recall)\n",
      "\n",
      "Random Forest\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.5328 (Higher is better)\n",
      "ROC-AUC:    0.5248 (Higher is better | 1.0 = Perfect)\n",
      "Precision:  0.3760 (Of predicted wins, how many correct?)\n",
      "Recall:     0.3964 (Of actual wins, how many caught?)\n",
      "F1-Score:   0.3859 (Balance between precision & recall)\n",
      "\n",
      "Gradient Boosting\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.6013 (Higher is better)\n",
      "ROC-AUC:    0.5496 (Higher is better | 1.0 = Perfect)\n",
      "Precision:  0.4181 (Of predicted wins, how many correct?)\n",
      "Recall:     0.1952 (Of actual wins, how many caught?)\n",
      "F1-Score:   0.2661 (Balance between precision & recall)\n",
      "\n",
      "XGradient Boosting\n",
      "--------------------------------------------------\n",
      "Accuracy:   0.5291 (Higher is better)\n",
      "ROC-AUC:    0.5410 (Higher is better | 1.0 = Perfect)\n",
      "Precision:  0.3950 (Of predicted wins, how many correct?)\n",
      "Recall:     0.5111 (Of actual wins, how many caught?)\n",
      "F1-Score:   0.4456 (Balance between precision & recall)\n"
     ]
    }
   ],
   "source": [
    "for model_name in models.keys():\n",
    "    y_pred = results[model_name]['val_pred']\n",
    "    y_proba = results[model_name]['val_proba']\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    roc_auc = roc_auc_score(y_val, y_proba)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    \n",
    "    evaluation_data.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Accuracy:   {accuracy:.4f} (Higher is better)\")\n",
    "    print(f\"ROC-AUC:    {roc_auc:.4f} (Higher is better | 1.0 = Perfect)\")\n",
    "    print(f\"Precision:  {precision:.4f} (Of predicted wins, how many correct?)\")\n",
    "    print(f\"Recall:     {recall:.4f} (Of actual wins, how many caught?)\")\n",
    "    print(f\"F1-Score:   {f1:.4f} (Balance between precision & recall)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330d60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "MODEL COMPARISON (Sorted by ROC-AUC)\n",
      "==================================================\n",
      "              Model  Accuracy  ROC-AUC  Precision   Recall  F1-Score\n",
      "  Gradient Boosting  0.601341 0.549636   0.418103 0.195171  0.266118\n",
      " XGradient Boosting  0.529061 0.541050   0.395023 0.511066  0.445614\n",
      "      Random Forest  0.532787 0.524820   0.375954 0.396378  0.385896\n",
      "Logistic Regression  0.507452 0.503163   0.372671 0.482897  0.420684\n"
     ]
    }
   ],
   "source": [
    "# Create evaluation dataframe\n",
    "eval_df = pd.DataFrame(evaluation_data)\n",
    "eval_df = eval_df.sort_values('ROC-AUC', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MODEL COMPARISON (Sorted by ROC-AUC)\")\n",
    "print(\"=\" * 50)\n",
    "print(eval_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24448ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "THRESHOLD OPTIMIZATION FOR BEST MODEL\n",
      "================================================================================\n",
      "\n",
      "Best Model: Gradient Boosting (ROC-AUC: 0.5496)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# NEW: THRESHOLD OPTIMIZATION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"THRESHOLD OPTIMIZATION FOR BEST MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select best model\n",
    "best_model_name = eval_df.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "best_proba = results[best_model_name]['val_proba']\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} (ROC-AUC: {eval_df.iloc[0]['ROC-AUC']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7428965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.370343</td>\n",
       "      <td>0.370343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540511</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.371088</td>\n",
       "      <td>0.370619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.540805</td>\n",
       "      <td>0.500592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.379285</td>\n",
       "      <td>0.373494</td>\n",
       "      <td>0.997988</td>\n",
       "      <td>0.543562</td>\n",
       "      <td>0.506686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.400149</td>\n",
       "      <td>0.380249</td>\n",
       "      <td>0.983903</td>\n",
       "      <td>0.548514</td>\n",
       "      <td>0.520354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.418033</td>\n",
       "      <td>0.381072</td>\n",
       "      <td>0.915493</td>\n",
       "      <td>0.538143</td>\n",
       "      <td>0.520468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.443368</td>\n",
       "      <td>0.383178</td>\n",
       "      <td>0.824950</td>\n",
       "      <td>0.523293</td>\n",
       "      <td>0.521942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.479881</td>\n",
       "      <td>0.388704</td>\n",
       "      <td>0.706237</td>\n",
       "      <td>0.501429</td>\n",
       "      <td>0.526491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.529806</td>\n",
       "      <td>0.403179</td>\n",
       "      <td>0.561368</td>\n",
       "      <td>0.469302</td>\n",
       "      <td>0.536305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.559613</td>\n",
       "      <td>0.410305</td>\n",
       "      <td>0.432596</td>\n",
       "      <td>0.421156</td>\n",
       "      <td>0.533458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.589419</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.301811</td>\n",
       "      <td>0.352526</td>\n",
       "      <td>0.530195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.601341</td>\n",
       "      <td>0.418103</td>\n",
       "      <td>0.195171</td>\n",
       "      <td>0.266118</td>\n",
       "      <td>0.517704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.615499</td>\n",
       "      <td>0.431655</td>\n",
       "      <td>0.120724</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.513617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.630402</td>\n",
       "      <td>0.506849</td>\n",
       "      <td>0.074447</td>\n",
       "      <td>0.129825</td>\n",
       "      <td>0.515922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.628167</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.032193</td>\n",
       "      <td>0.060264</td>\n",
       "      <td>0.505446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.631893</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.505504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.630402</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.501420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.630402</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.501006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.629657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.629657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.629657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  Accuracy  Precision    Recall  F1-Score  ROC-Score\n",
       "0        0.00  0.370343   0.370343  1.000000  0.540511   0.500000\n",
       "1        0.05  0.371088   0.370619  1.000000  0.540805   0.500592\n",
       "2        0.10  0.379285   0.373494  0.997988  0.543562   0.506686\n",
       "3        0.15  0.400149   0.380249  0.983903  0.548514   0.520354\n",
       "4        0.20  0.418033   0.381072  0.915493  0.538143   0.520468\n",
       "5        0.25  0.443368   0.383178  0.824950  0.523293   0.521942\n",
       "6        0.30  0.479881   0.388704  0.706237  0.501429   0.526491\n",
       "7        0.35  0.529806   0.403179  0.561368  0.469302   0.536305\n",
       "8        0.40  0.559613   0.410305  0.432596  0.421156   0.533458\n",
       "9        0.45  0.589419   0.423729  0.301811  0.352526   0.530195\n",
       "10       0.50  0.601341   0.418103  0.195171  0.266118   0.517704\n",
       "11       0.55  0.615499   0.431655  0.120724  0.188679   0.513617\n",
       "12       0.60  0.630402   0.506849  0.074447  0.129825   0.515922\n",
       "13       0.65  0.628167   0.470588  0.032193  0.060264   0.505446\n",
       "14       0.70  0.631893   0.600000  0.018109  0.035156   0.505504\n",
       "15       0.75  0.630402   0.666667  0.004024  0.008000   0.501420\n",
       "16       0.80  0.630402   1.000000  0.002012  0.004016   0.501006\n",
       "17       0.85  0.629657   0.000000  0.000000  0.000000   0.500000\n",
       "18       0.90  0.629657   0.000000  0.000000  0.000000   0.500000\n",
       "19       0.95  0.629657   0.000000  0.000000  0.000000   0.500000"
      ]
     },
     "execution_count": 2676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test different thresholds\n",
    "#thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "thresholds = np.linspace(0, 1, 21)\n",
    "threshold_results = []\n",
    "\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (best_proba >= threshold).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred_threshold)\n",
    "    precision = precision_score(y_val, y_pred_threshold, zero_division=0)\n",
    "    recall = recall_score(y_val, y_pred_threshold, zero_division=0)\n",
    "    f1 = f1_score(y_val, y_pred_threshold, zero_division=0)\n",
    "    roc = roc_auc_score(y_val, y_pred_threshold)\n",
    "    \n",
    "    threshold_results.append({\n",
    "        'Threshold': threshold,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-Score': roc\n",
    "    })\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_results)\n",
    "\n",
    "threshold_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470a6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "OPTIMAL THRESHOLDS FOR DIFFERENT OBJECTIVES\n",
      "==================================================\n",
      "\n",
      "1. BALANCED PERFORMANCE (Max F1-Score)\n",
      "   Threshold: 0.15\n",
      "   Accuracy:  0.4001\n",
      "   Precision: 0.3802\n",
      "   Recall:    0.9839\n",
      "   F1-Score:  0.5485\n",
      "\n",
      "2. MAXIMUM ACCURACY\n",
      "   Threshold: 0.70\n",
      "   Accuracy:  0.6319\n",
      "   Precision: 0.6000\n",
      "   Recall:    0.0181\n",
      "   F1-Score:  0.0352\n",
      "\n",
      "3. HIGH PRECISION (Confident Wins - Few False Positives)\n",
      "   Threshold: 0.80\n",
      "   Accuracy:  0.6304\n",
      "   Precision: 1.0000\n",
      "   Recall:    0.0020\n",
      "   F1-Score:  0.0040\n",
      "   → Use when: You want to focus only on deals you're VERY confident will win\n",
      "\n",
      "4. HIGH RECALL (Catch All Potential Wins)\n",
      "   Threshold: 0.00\n",
      "   Accuracy:  0.3703\n",
      "   Precision: 0.3703\n",
      "   Recall:    1.0000\n",
      "   F1-Score:  0.5405\n",
      "   → Use when: You don't want to miss any winnable deals\n"
     ]
    }
   ],
   "source": [
    "# Find optimal thresholds for different objectives\n",
    "optimal_accuracy_idx = threshold_df['Accuracy'].idxmax()\n",
    "optimal_f1_idx = threshold_df['F1-Score'].idxmax()\n",
    "optimal_precision_idx = threshold_df['Precision'].idxmax()\n",
    "optimal_recall_idx = threshold_df['Recall'].idxmax()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"OPTIMAL THRESHOLDS FOR DIFFERENT OBJECTIVES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n1. BALANCED PERFORMANCE (Max F1-Score)\")\n",
    "print(f\"   Threshold: {threshold_df.loc[optimal_f1_idx, 'Threshold']:.2f}\")\n",
    "print(f\"   Accuracy:  {threshold_df.loc[optimal_f1_idx, 'Accuracy']:.4f}\")\n",
    "print(f\"   Precision: {threshold_df.loc[optimal_f1_idx, 'Precision']:.4f}\")\n",
    "print(f\"   Recall:    {threshold_df.loc[optimal_f1_idx, 'Recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {threshold_df.loc[optimal_f1_idx, 'F1-Score']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. MAXIMUM ACCURACY\")\n",
    "print(f\"   Threshold: {threshold_df.loc[optimal_accuracy_idx, 'Threshold']:.2f}\")\n",
    "print(f\"   Accuracy:  {threshold_df.loc[optimal_accuracy_idx, 'Accuracy']:.4f}\")\n",
    "print(f\"   Precision: {threshold_df.loc[optimal_accuracy_idx, 'Precision']:.4f}\")\n",
    "print(f\"   Recall:    {threshold_df.loc[optimal_accuracy_idx, 'Recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {threshold_df.loc[optimal_accuracy_idx, 'F1-Score']:.4f}\")\n",
    "\n",
    "print(f\"\\n3. HIGH PRECISION (Confident Wins - Few False Positives)\")\n",
    "print(f\"   Threshold: {threshold_df.loc[optimal_precision_idx, 'Threshold']:.2f}\")\n",
    "print(f\"   Accuracy:  {threshold_df.loc[optimal_precision_idx, 'Accuracy']:.4f}\")\n",
    "print(f\"   Precision: {threshold_df.loc[optimal_precision_idx, 'Precision']:.4f}\")\n",
    "print(f\"   Recall:    {threshold_df.loc[optimal_precision_idx, 'Recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {threshold_df.loc[optimal_precision_idx, 'F1-Score']:.4f}\")\n",
    "print(f\"   → Use when: You want to focus only on deals you're VERY confident will win\")\n",
    "\n",
    "print(f\"\\n4. HIGH RECALL (Catch All Potential Wins)\")\n",
    "print(f\"   Threshold: {threshold_df.loc[optimal_recall_idx, 'Threshold']:.2f}\")\n",
    "print(f\"   Accuracy:  {threshold_df.loc[optimal_recall_idx, 'Accuracy']:.4f}\")\n",
    "print(f\"   Precision: {threshold_df.loc[optimal_recall_idx, 'Precision']:.4f}\")\n",
    "print(f\"   Recall:    {threshold_df.loc[optimal_recall_idx, 'Recall']:.4f}\")\n",
    "print(f\"   F1-Score:  {threshold_df.loc[optimal_recall_idx, 'F1-Score']:.4f}\")\n",
    "print(f\"   → Use when: You don't want to miss any winnable deals\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaebdfa",
   "metadata": {},
   "source": [
    "full_train = pd.concat([df_train, df_val], axis=0).reset_index(drop=True)\n",
    "len(full_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
